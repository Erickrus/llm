{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeDkjYZ1xiyjRIYbHLOaSG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Erickrus/llm/blob/main/deepspeed_cifar_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        " <img src=\"https://raw.githubusercontent.com/microsoft/DeepSpeed/master/docs/assets/images/DeepSpeed_light.svg#gh-light-mode-only\" width=\"400px\">\n",
        "</div>\n",
        "\n",
        "Extreme Speed and Scale for DL Training and Inference\n",
        "\n",
        "[DeepSpeed](https://www.deepspeed.ai/) is an easy-to-use deep learning optimization software suite that enables unprecedented scale and speed for Deep Learning Training and Inference. With DeepSpeed you can:\n",
        "\n",
        "* Train/Inference dense or sparse models with billions or trillions of parameters\n",
        "* Achieve excellent system throughput and efficiently scale to thousands of GPUs\n",
        "* Train/Inference on resource constrained GPU systems\n",
        "* Achieve unprecedented low latency and high throughput for inference\n",
        "* Achieve extreme compression for an unparalleled inference latency and model size reduction with low costs"
      ],
      "metadata": {
        "id": "P0zseLVu5l8y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "MP3H38F7yFk3",
        "outputId": "cd31c474-dcc2-4257-81de-93283ae58a84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-04 06:08:32--  https://raw.githubusercontent.com/microsoft/DeepSpeedExamples/master/training/cifar/cifar10_tutorial.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12658 (12K) [text/plain]\n",
            "Saving to: ‘cifar10_tutorial.py’\n",
            "\n",
            "\rcifar10_tutorial.py   0%[                    ]       0  --.-KB/s               \rcifar10_tutorial.py 100%[===================>]  12.36K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-04 06:08:32 (85.2 MB/s) - ‘cifar10_tutorial.py’ saved [12658/12658]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title download cifar10 files\n",
        "\n",
        "#@markdown\n",
        "!wget https://raw.githubusercontent.com/microsoft/DeepSpeedExamples/master/training/cifar/cifar10_tutorial.py\n",
        "!wget https://raw.githubusercontent.com/microsoft/DeepSpeedExamples/master/training/cifar/cifar10_deepspeed.py\n",
        "!wget https://raw.githubusercontent.com/microsoft/DeepSpeedExamples/master/training/cifar/ds_config.json\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title install packages\n",
        "\n",
        "!pip3 install deepspeed mpi4py"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_u86gS28yeC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title define FabUtil\n",
        "\n",
        "#@markdown FabUtil\n",
        "import os\n",
        "import json\n",
        "\n",
        "import tarfile\n",
        "from zipfile import ZipFile\n",
        "from google.colab._system_commands import _shell_line_magic as shell_line_magic\n",
        "\n",
        "\n",
        "class FabUtil:\n",
        "  def cust_code(self, codeFilename, content):\n",
        "    self._ensure_dir(codeFilename)\n",
        "    with open(codeFilename, 'w') as f:\n",
        "      f.write(content)\n",
        "\n",
        "  def fabricate(self, fabs):\n",
        "    # accept both filename and fabs object\n",
        "    if type(fabs) == str:\n",
        "      with open(fabs, \"r\") as f:\n",
        "        fabs = json.loads(fabs)\n",
        "    elif type(fabs) == dict:\n",
        "      pass\n",
        "\n",
        "    for i in range(len(fabs[\"fabs\"])):\n",
        "      fab = fabs[\"fabs\"][i]\n",
        "      if \"cmd\" in fab:\n",
        "        print(\"%s\" % fab[\"cmd\"])\n",
        "        shell_line_magic(\"%s\" % fab[\"cmd\"])\n",
        "        #os.system(\"%s\" % fab[\"cmd\"])\n",
        "        continue\n",
        "\n",
        "      if \"patches\" in fab:\n",
        "        self._patch(fab[\"srcFilename\"], fab[\"patches\"])\n",
        "        continue\n",
        "\n",
        "      entryFilename = \"\"\n",
        "      srcFilename = fab[\"srcFilename\"]\n",
        "      if srcFilename.find(\"::\") > 0:\n",
        "        srcFilename, entryFilename = srcFilename.split(\"::\")\n",
        "      tgtFilename = fab[\"tgtFilename\"]\n",
        "      srcFilename = os.path.join(fabs[\"baseDir\"], srcFilename)\n",
        "\n",
        "      if entryFilename != \"\":\n",
        "        self._process_zip_file(srcFilename, entryFilename, tgtFilename)\n",
        "      else:\n",
        "        self._ensure_dir(tgtFilename)\n",
        "        os.system(\"cp %s %s\" % (srcFilename, tgtFilename))\n",
        "        print(\"fabricated %s ==> %s\" % (srcFilename, tgtFilename))\n",
        "\n",
        "  def _patch(self, filename, patches):\n",
        "    changed = False\n",
        "    with open(filename, 'r') as f:\n",
        "      lines = f.read().split('\\n')\n",
        "    for patchItem in patches:\n",
        "      lineNum = patchItem['lineNum']\n",
        "      fromText = patchItem['fromText']\n",
        "      toText = patchItem['toText']\n",
        "      if lines[lineNum-1] == fromText:\n",
        "        lines[lineNum-1] = toText\n",
        "        changed = True\n",
        "    if changed:\n",
        "      with open(filename, 'w') as f:\n",
        "        f.write('\\n'.join(lines))\n",
        "\n",
        "  def _ensure_dir(self, tgtFilename):\n",
        "    dirName = os.path.dirname(tgtFilename)\n",
        "    if not os.path.exists(dirName):\n",
        "      os.system(\"mkdir -p %s \" % dirName)\n",
        "\n",
        "  def _process_zip_file(self, srcFilename, entryFilename, tgtFilename):\n",
        "    try:\n",
        "      if srcFilename.lower().find(\".tar\") > 0 or srcFilename.lower().find(\".tgz\") > 0:\n",
        "        fileOp = 'r'\n",
        "        if srcFilename.lower().endswith('.tar.gz') or srcFilename.lower().endswith('.tgz'): # gzip\n",
        "            fileOp = 'r:gz'\n",
        "        elif srcFilename.lower().endswith('.tar.bz2'): # bzip2\n",
        "            fileOp = 'r:bz2'\n",
        "        elif srcFilename.lower().endswith('.tar.xz'): # lzma\n",
        "            fileOp = 'r:xz'\n",
        "        with tarfile.open(srcFilename, fileOp) as tar:\n",
        "          self._ensure_dir(tgtFilename)\n",
        "          with open(tgtFilename, \"wb\") as f:\n",
        "            f.write(tar.extractfile(entryFilename).read())\n",
        "        print(\"fabricated %s::%s ==> %s\" % (srcFilename, entryFilename, tgtFilename))\n",
        "        return\n",
        "      if srcFilename.lower().find(\".zip\") >0:\n",
        "        with ZipFile(srcFilename, 'r') as z:\n",
        "          self._ensure_dir(tgtFilename)\n",
        "          with open(tgtFilename, \"wb\") as f:\n",
        "            f.write(z.read(entryFilename))\n",
        "        print(\"fabricated %s::%s ==> %s\" % (srcFilename, entryFilename, tgtFilename))\n",
        "        return\n",
        "    except:\n",
        "      print(\"failed %s::%s ==> %s\" % (srcFilename, entryFilename, tgtFilename))\n",
        "      return\n",
        "    print(\"not found %s::%s ==> %s\" % (srcFilename, entryFilename, tgtFilename))\n",
        "\n",
        "fb = FabUtil()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "APKroP0G1ZBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title modify cifar10_deepspeed.py\n",
        "\n",
        "fb.fabricate({\n",
        "  \"baseDir\": \"/content/\",\n",
        "  \"fabs\": [\n",
        "  {\n",
        "        #@markdown Resolve: AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute 'next'\n",
        "        #@markdown\n",
        "        #@markdown https://stackoverflow.com/questions/74289077/attributeerror-multiprocessingdataloaderiter-object-has-no-attribute-next\n",
        "        \"srcFilename\": \"cifar10_deepspeed.py\",\n",
        "        \"patches\": [{\n",
        "        \"lineNum\": 162,\n",
        "        \"fromText\": 'images, labels = dataiter.next()',\n",
        "        \"toText\":   'images, labels = next(dataiter)',\n",
        "        },\n",
        "        {\n",
        "        \"lineNum\": 312,\n",
        "        \"fromText\": 'images, labels = dataiter.next()',\n",
        "        \"toText\":   'images, labels = next(dataiter)',\n",
        "        }\n",
        "        ]\n",
        "    }\n",
        "  ]\n",
        "})"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IDF-fTPw1jMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat ds_config.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpDw5rtD7npw",
        "outputId": "3e59cfa8-e7a2-4a5a-fcda-4e3271196adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"train_batch_size\": 16,\n",
            "  \"steps_per_print\": 2000,\n",
            "  \"optimizer\": {\n",
            "    \"type\": \"Adam\",\n",
            "    \"params\": {\n",
            "      \"lr\": 0.001,\n",
            "      \"betas\": [\n",
            "        0.8,\n",
            "        0.999\n",
            "      ],\n",
            "      \"eps\": 1e-8,\n",
            "      \"weight_decay\": 3e-7\n",
            "    }\n",
            "  },\n",
            "  \"scheduler\": {\n",
            "    \"type\": \"WarmupLR\",\n",
            "    \"params\": {\n",
            "      \"warmup_min_lr\": 0,\n",
            "      \"warmup_max_lr\": 0.001,\n",
            "      \"warmup_num_steps\": 1000\n",
            "    }\n",
            "  },\n",
            "  \"gradient_clipping\": 1.0,\n",
            "  \"prescale_gradients\": false,\n",
            "  \"fp16\": {\n",
            "      \"enabled\": true,\n",
            "      \"fp16_master_weights_and_grads\": false,\n",
            "      \"loss_scale\": 0,\n",
            "      \"loss_scale_window\": 500,\n",
            "      \"hysteresis\": 2,\n",
            "      \"min_loss_scale\": 1,\n",
            "      \"initial_scale_power\": 15\n",
            "  },\n",
            "  \"wall_clock_breakdown\": false,\n",
            "  \"zero_optimization\": {\n",
            "      \"stage\": 0,\n",
            "      \"allgather_partitions\": true,\n",
            "      \"reduce_scatter\": true,\n",
            "      \"allgather_bucket_size\": 50000000,\n",
            "      \"reduce_bucket_size\": 50000000,\n",
            "      \"overlap_comm\": true,\n",
            "      \"contiguous_gradients\": true,\n",
            "      \"cpu_offload\": false\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run cifar10_deepspeed.py\n",
        "#@markdown ```shell\n",
        "#@markdown deepspeed cifar10_deepspeed.py \\\n",
        "#@markdown --deepspeed \\\n",
        "#@markdown --deepspeed_config ds_config.json\n",
        "#@markdown\n",
        "#@markdown ```\n",
        "!deepspeed cifar10_deepspeed.py --deepspeed --deepspeed_config ds_config.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "K_msWHWiyW6l",
        "outputId": "ef4a9a9a-8bac-4cf3-85e3-2fb755c5f921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-04-04 06:02:17,177] [WARNING] [runner.py:186:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2023-04-04 06:02:17,191] [INFO] [runner.py:550:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None cifar10_deepspeed.py --deepspeed --deepspeed_config ds_config.json\n",
            "[2023-04-04 06:02:19,346] [INFO] [launch.py:135:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.16.2-1+cuda11.8\n",
            "[2023-04-04 06:02:19,346] [INFO] [launch.py:135:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.16.2-1\n",
            "[2023-04-04 06:02:19,346] [INFO] [launch.py:135:main] 0 NCCL_VERSION=2.16.2-1\n",
            "[2023-04-04 06:02:19,346] [INFO] [launch.py:135:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2023-04-04 06:02:19,346] [INFO] [launch.py:135:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.16.2-1+cuda11.8\n",
            "[2023-04-04 06:02:19,346] [INFO] [launch.py:135:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2023-04-04 06:02:19,346] [INFO] [launch.py:135:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.16.2-1\n",
            "[2023-04-04 06:02:19,347] [INFO] [launch.py:142:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2023-04-04 06:02:19,347] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2023-04-04 06:02:19,347] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2023-04-04 06:02:19,347] [INFO] [launch.py:162:main] dist_world_size=1\n",
            "[2023-04-04 06:02:19,347] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[2023-04-04 06:02:21,610] [INFO] [comm.py:652:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Figure(640x480)\n",
            "plane  frog plane  deer\n",
            "[2023-04-04 06:02:25,803] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed info: version=0.8.3, git-hash=unknown, git-branch=unknown\n",
            "[2023-04-04 06:02:25,806] [WARNING] [config_utils.py:75:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead\n",
            "[2023-04-04 06:02:25,904] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "Using /root/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py39_cu118/fused_adam/build.ninja...\n",
            "Building extension module fused_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module fused_adam...\n",
            "Time to load fused_adam op: 0.2236189842224121 seconds\n",
            "[2023-04-04 06:02:27,474] [INFO] [logging.py:93:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adam as basic optimizer\n",
            "[2023-04-04 06:02:27,475] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
            "[2023-04-04 06:02:27,475] [INFO] [logging.py:93:log_dist] [Rank 0] Creating fp16 optimizer with dynamic loss scale\n",
            "[2023-04-04 06:02:27,477] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam\n",
            "[2023-04-04 06:02:27,477] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupLR\n",
            "[2023-04-04 06:02:27,477] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7ff3a10c4490>\n",
            "[2023-04-04 06:02:27,477] [INFO] [logging.py:93:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[[0.8, 0.999]]\n",
            "[2023-04-04 06:02:27,477] [INFO] [config.py:1018:print] DeepSpeedEngine configuration:\n",
            "[2023-04-04 06:02:27,478] [INFO] [config.py:1022:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2023-04-04 06:02:27,478] [INFO] [config.py:1022:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2023-04-04 06:02:27,478] [INFO] [config.py:1022:print]   amp_enabled .................. False\n",
            "[2023-04-04 06:02:27,478] [INFO] [config.py:1022:print]   amp_params ................... False\n",
            "[2023-04-04 06:02:27,478] [INFO] [config.py:1022:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": \"autotuning_results\", \n",
            "    \"exps_dir\": \"autotuning_exps\", \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2023-04-04 06:02:27,478] [INFO] [config.py:1022:print]   bfloat16_enabled ............. False\n",
            "[2023-04-04 06:02:27,478] [INFO] [config.py:1022:print]   checkpoint_parallel_write_pipeline  False\n",
            "[2023-04-04 06:02:27,478] [INFO] [config.py:1022:print]   checkpoint_tag_validation_enabled  True\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   checkpoint_tag_validation_fail  False\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7ff3a7b8c730>\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   communication_data_type ...... None\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   curriculum_enabled_legacy .... False\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   curriculum_params_legacy ..... False\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   data_efficiency_enabled ...... False\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   dataloader_drop_last ......... False\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   disable_allgather ............ False\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   dump_state ................... False\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   dynamic_loss_scale_args ...... {'init_scale': 32768, 'scale_window': 500, 'delayed_shift': 2, 'min_scale': 1}\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   eigenvalue_enabled ........... False\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   eigenvalue_layer_num ......... 0\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   eigenvalue_max_iter .......... 100\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   eigenvalue_stability ......... 1e-06\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   eigenvalue_tol ............... 0.01\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   eigenvalue_verbose ........... False\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   elasticity_enabled ........... False\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   fp16_auto_cast ............... False\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   fp16_enabled ................. True\n",
            "[2023-04-04 06:02:27,479] [INFO] [config.py:1022:print]   fp16_master_weights_and_gradients  False\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   global_rank .................. 0\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   grad_accum_dtype ............. None\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   gradient_accumulation_steps .. 1\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   gradient_clipping ............ 1\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   gradient_predivide_factor .... 1.0\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   initial_dynamic_scale ........ 32768\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   load_universal_checkpoint .... False\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   loss_scale ................... 0\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   memory_breakdown ............. False\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   optimizer_legacy_fusion ...... False\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   optimizer_name ............... adam\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   optimizer_params ............. {'lr': 0.001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   pld_enabled .................. False\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   pld_params ................... False\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   prescale_gradients ........... False\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   scheduler_name ............... WarmupLR\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 0.001, 'warmup_num_steps': 1000}\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   sparse_attention ............. None\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   sparse_gradients_enabled ..... False\n",
            "[2023-04-04 06:02:27,480] [INFO] [config.py:1022:print]   steps_per_print .............. 2000\n",
            "[2023-04-04 06:02:27,481] [INFO] [config.py:1022:print]   train_batch_size ............. 16\n",
            "[2023-04-04 06:02:27,481] [INFO] [config.py:1022:print]   train_micro_batch_size_per_gpu  16\n",
            "[2023-04-04 06:02:27,481] [INFO] [config.py:1022:print]   use_node_local_storage ....... False\n",
            "[2023-04-04 06:02:27,481] [INFO] [config.py:1022:print]   wall_clock_breakdown ......... False\n",
            "[2023-04-04 06:02:27,481] [INFO] [config.py:1022:print]   world_size ................... 1\n",
            "[2023-04-04 06:02:27,481] [INFO] [config.py:1022:print]   zero_allow_untested_optimizer  False\n",
            "[2023-04-04 06:02:27,481] [INFO] [config.py:1022:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=50000000 allgather_partitions=True allgather_bucket_size=50000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False\n",
            "[2023-04-04 06:02:27,481] [INFO] [config.py:1022:print]   zero_enabled ................. False\n",
            "[2023-04-04 06:02:27,481] [INFO] [config.py:1022:print]   zero_force_ds_cpu_optimizer .. True\n",
            "[2023-04-04 06:02:27,481] [INFO] [config.py:1022:print]   zero_optimization_stage ...... 0\n",
            "[2023-04-04 06:02:27,481] [INFO] [config.py:1007:print_user_config]   json = {\n",
            "    \"train_batch_size\": 16, \n",
            "    \"steps_per_print\": 2.000000e+03, \n",
            "    \"optimizer\": {\n",
            "        \"type\": \"Adam\", \n",
            "        \"params\": {\n",
            "            \"lr\": 0.001, \n",
            "            \"betas\": [0.8, 0.999], \n",
            "            \"eps\": 1e-08, \n",
            "            \"weight_decay\": 3e-07\n",
            "        }\n",
            "    }, \n",
            "    \"scheduler\": {\n",
            "        \"type\": \"WarmupLR\", \n",
            "        \"params\": {\n",
            "            \"warmup_min_lr\": 0, \n",
            "            \"warmup_max_lr\": 0.001, \n",
            "            \"warmup_num_steps\": 1000\n",
            "        }\n",
            "    }, \n",
            "    \"gradient_clipping\": 1, \n",
            "    \"prescale_gradients\": false, \n",
            "    \"fp16\": {\n",
            "        \"enabled\": true, \n",
            "        \"fp16_master_weights_and_grads\": false, \n",
            "        \"loss_scale\": 0, \n",
            "        \"loss_scale_window\": 500, \n",
            "        \"hysteresis\": 2, \n",
            "        \"min_loss_scale\": 1, \n",
            "        \"initial_scale_power\": 15\n",
            "    }, \n",
            "    \"wall_clock_breakdown\": false, \n",
            "    \"zero_optimization\": {\n",
            "        \"stage\": 0, \n",
            "        \"allgather_partitions\": true, \n",
            "        \"reduce_scatter\": true, \n",
            "        \"allgather_bucket_size\": 5.000000e+07, \n",
            "        \"reduce_bucket_size\": 5.000000e+07, \n",
            "        \"overlap_comm\": true, \n",
            "        \"contiguous_gradients\": true, \n",
            "        \"cpu_offload\": false\n",
            "    }\n",
            "}\n",
            "Using /root/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py39_cu118/utils/build.ninja...\n",
            "Building extension module utils...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.21610069274902344 seconds\n",
            "fp16=True\n",
            "[2023-04-04 06:02:31,820] [INFO] [fused_optimizer.py:383:_update_scale] \n",
            "Grad overflow on iteration 344\n",
            "[2023-04-04 06:02:31,821] [INFO] [fused_optimizer.py:384:_update_scale] Reducing dynamic loss scale from 32768 to 16384.0\n",
            "[2023-04-04 06:02:31,823] [INFO] [logging.py:93:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32768, reducing to 16384.0\n",
            "[2023-04-04 06:02:35,633] [INFO] [fused_optimizer.py:393:_update_scale] No Grad overflow for 500 iterations\n",
            "[2023-04-04 06:02:35,633] [INFO] [fused_optimizer.py:395:_update_scale] Increasing dynamic loss scale from 16384.0 to 32768.0\n",
            "[2023-04-04 06:02:35,866] [INFO] [fused_optimizer.py:383:_update_scale] \n",
            "Grad overflow on iteration 877\n",
            "[2023-04-04 06:02:35,866] [INFO] [fused_optimizer.py:384:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0\n",
            "[2023-04-04 06:02:35,867] [INFO] [logging.py:93:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0\n",
            "[2023-04-04 06:02:40,526] [INFO] [fused_optimizer.py:393:_update_scale] No Grad overflow for 500 iterations\n",
            "[2023-04-04 06:02:40,526] [INFO] [fused_optimizer.py:395:_update_scale] Increasing dynamic loss scale from 16384.0 to 32768.0\n",
            "[2023-04-04 06:02:40,779] [INFO] [fused_optimizer.py:383:_update_scale] \n",
            "Grad overflow on iteration 1411\n",
            "[2023-04-04 06:02:40,779] [INFO] [fused_optimizer.py:384:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0\n",
            "[2023-04-04 06:02:40,779] [INFO] [logging.py:93:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0\n",
            "[2023-04-04 06:02:44,550] [INFO] [fused_optimizer.py:393:_update_scale] No Grad overflow for 500 iterations\n",
            "[2023-04-04 06:02:44,550] [INFO] [fused_optimizer.py:395:_update_scale] Increasing dynamic loss scale from 16384.0 to 32768.0\n",
            "[2023-04-04 06:02:44,584] [INFO] [fused_optimizer.py:383:_update_scale] \n",
            "Grad overflow on iteration 1917\n",
            "[2023-04-04 06:02:44,584] [INFO] [fused_optimizer.py:384:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0\n",
            "[2023-04-04 06:02:44,584] [INFO] [logging.py:93:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0\n",
            "[2023-04-04 06:02:45,212] [INFO] [logging.py:93:log_dist] [Rank 0] step=2000, skipped=4, lr=[0.001], mom=[[0.8, 0.999]]\n",
            "[2023-04-04 06:02:45,212] [INFO] [timer.py:198:stop] epoch=0/micro_step=2000/global_step=2000, RunningAvgSamplesPerSec=2023.2353667010555, CurrSamplesPerSec=2078.9610904584883, MemAllocated=0.02GB, MaxMemAllocated=0.02GB\n",
            "[1,  2000] loss: 1.684\n",
            "[2023-04-04 06:02:48,430] [INFO] [fused_optimizer.py:393:_update_scale] No Grad overflow for 500 iterations\n",
            "[2023-04-04 06:02:48,430] [INFO] [fused_optimizer.py:395:_update_scale] Increasing dynamic loss scale from 16384.0 to 32768.0\n",
            "[2023-04-04 06:02:48,816] [INFO] [fused_optimizer.py:383:_update_scale] \n",
            "Grad overflow on iteration 2465\n",
            "[2023-04-04 06:02:48,816] [INFO] [fused_optimizer.py:384:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0\n",
            "[2023-04-04 06:02:48,816] [INFO] [logging.py:93:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0\n",
            "[2023-04-04 06:02:53,444] [INFO] [fused_optimizer.py:393:_update_scale] No Grad overflow for 500 iterations\n",
            "[2023-04-04 06:02:53,444] [INFO] [fused_optimizer.py:395:_update_scale] Increasing dynamic loss scale from 16384.0 to 32768.0\n",
            "[2023-04-04 06:02:53,520] [INFO] [fused_optimizer.py:383:_update_scale] \n",
            "Grad overflow on iteration 2976\n",
            "[2023-04-04 06:02:53,520] [INFO] [fused_optimizer.py:384:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0\n",
            "[2023-04-04 06:02:53,520] [INFO] [logging.py:93:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0\n",
            "[2023-04-04 06:02:57,352] [INFO] [fused_optimizer.py:393:_update_scale] No Grad overflow for 500 iterations\n",
            "[2023-04-04 06:02:57,352] [INFO] [fused_optimizer.py:395:_update_scale] Increasing dynamic loss scale from 16384.0 to 32768.0\n",
            "[2023-04-04 06:02:57,443] [INFO] [fused_optimizer.py:383:_update_scale] \n",
            "Grad overflow on iteration 3489\n",
            "[2023-04-04 06:02:57,443] [INFO] [fused_optimizer.py:384:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0\n",
            "[2023-04-04 06:02:57,444] [INFO] [logging.py:93:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0\n",
            "[2023-04-04 06:03:01,280] [INFO] [fused_optimizer.py:393:_update_scale] No Grad overflow for 500 iterations\n",
            "[2023-04-04 06:03:01,280] [INFO] [fused_optimizer.py:395:_update_scale] Increasing dynamic loss scale from 16384.0 to 32768.0\n",
            "[2023-04-04 06:03:01,340] [INFO] [logging.py:93:log_dist] [Rank 0] step=4000, skipped=7, lr=[0.001], mom=[[0.8, 0.999]]\n",
            "[2023-04-04 06:03:01,341] [INFO] [timer.py:198:stop] epoch=0/micro_step=4000/global_step=4000, RunningAvgSamplesPerSec=2020.3109991405324, CurrSamplesPerSec=3002.6337360178973, MemAllocated=0.02GB, MaxMemAllocated=0.02GB\n",
            "[2023-04-04 06:03:01,385] [INFO] [fused_optimizer.py:383:_update_scale] \n",
            "Grad overflow on iteration 4004\n",
            "[2023-04-04 06:03:01,385] [INFO] [fused_optimizer.py:384:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0\n",
            "[2023-04-04 06:03:01,386] [INFO] [logging.py:93:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0\n",
            "[2023-04-04 06:03:06,051] [INFO] [fused_optimizer.py:393:_update_scale] No Grad overflow for 500 iterations\n",
            "[2023-04-04 06:03:06,052] [INFO] [fused_optimizer.py:395:_update_scale] Increasing dynamic loss scale from 16384.0 to 32768.0\n",
            "[2023-04-04 06:03:06,274] [INFO] [fused_optimizer.py:383:_update_scale] \n",
            "Grad overflow on iteration 4536\n",
            "[2023-04-04 06:03:06,275] [INFO] [fused_optimizer.py:384:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0\n",
            "[2023-04-04 06:03:06,280] [INFO] [logging.py:93:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0\n",
            "[2023-04-04 06:03:06,359] [INFO] [fused_optimizer.py:383:_update_scale] \n",
            "Grad overflow on iteration 4545\n",
            "[2023-04-04 06:03:06,359] [INFO] [fused_optimizer.py:384:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0\n",
            "[2023-04-04 06:03:06,359] [INFO] [logging.py:93:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 16384.0, reducing to 8192.0\n",
            "[2023-04-04 06:03:10,195] [INFO] [fused_optimizer.py:393:_update_scale] No Grad overflow for 500 iterations\n",
            "[2023-04-04 06:03:10,195] [INFO] [fused_optimizer.py:395:_update_scale] Increasing dynamic loss scale from 8192.0 to 16384.0\n",
            "[2,  2000] loss: 1.282\n",
            "[2023-04-04 06:03:13,988] [INFO] [fused_optimizer.py:393:_update_scale] No Grad overflow for 500 iterations\n",
            "[2023-04-04 06:03:13,988] [INFO] [fused_optimizer.py:395:_update_scale] Increasing dynamic loss scale from 16384.0 to 32768.0\n",
            "[2023-04-04 06:03:14,008] [INFO] [fused_optimizer.py:383:_update_scale] \n",
            "Grad overflow on iteration 5549\n",
            "[2023-04-04 06:03:14,008] [INFO] [fused_optimizer.py:384:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0\n",
            "[2023-04-04 06:03:14,008] [INFO] [logging.py:93:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0\n",
            "[2023-04-04 06:03:17,395] [INFO] [fused_optimizer.py:383:_update_scale] \n",
            "Grad overflow on iteration 5882\n",
            "[2023-04-04 06:03:17,395] [INFO] [fused_optimizer.py:384:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0\n",
            "[2023-04-04 06:03:17,396] [INFO] [logging.py:93:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 16384.0, reducing to 8192.0\n",
            "[2023-04-04 06:03:18,293] [INFO] [logging.py:93:log_dist] [Rank 0] step=6000, skipped=12, lr=[0.001], mom=[[0.8, 0.999]]\n",
            "[2023-04-04 06:03:18,294] [INFO] [timer.py:198:stop] epoch=0/micro_step=6000/global_step=6000, RunningAvgSamplesPerSec=1981.5562884928092, CurrSamplesPerSec=2790.041325406394, MemAllocated=0.02GB, MaxMemAllocated=0.02GB\n",
            "Finished Training\n",
            "Figure(640x480)\n",
            "GroundTruth:    cat  ship  ship plane\n",
            "Predicted:    cat  ship  ship plane\n",
            "Accuracy of the network on the 10000 test images: 56 %\n",
            "Accuracy of plane : 78 %\n",
            "Accuracy of   car : 70 %\n",
            "Accuracy of  bird : 49 %\n",
            "Accuracy of   cat : 30 %\n",
            "Accuracy of  deer : 38 %\n",
            "Accuracy of   dog : 42 %\n",
            "Accuracy of  frog : 57 %\n",
            "Accuracy of horse : 74 %\n",
            "Accuracy of  ship : 70 %\n",
            "Accuracy of truck : 51 %\n",
            "[2023-04-04 06:03:37,451] [INFO] [launch.py:350:main] Process 6044 exits successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title diff 2 files\n",
        "\n",
        "#@markdown for better compare, use this https://www.diffchecker.com/text-compare/\n",
        "!diff cifar10_tutorial.py cifar10_deepspeed.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "Lqr0VMHl4_mj",
        "outputId": "621ba42f-5fb3-4b4b-c7ac-217b84246009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1,33c1,5\n",
            "< # -*- coding: utf-8 -*-\n",
            "< \"\"\"\n",
            "< Training a Classifier\n",
            "< =====================\n",
            "< \n",
            "< This is it. You have seen how to define neural networks, compute loss and make\n",
            "< updates to the weights of the network.\n",
            "< \n",
            "< Now you might be thinking,\n",
            "< \n",
            "< What about data?\n",
            "< ----------------\n",
            "< \n",
            "< Generally, when you have to deal with image, text, audio or video data,\n",
            "< you can use standard python packages that load data into a numpy array.\n",
            "< Then you can convert this array into a ``torch.*Tensor``.\n",
            "< \n",
            "< -  For images, packages such as Pillow, OpenCV are useful\n",
            "< -  For audio, packages such as scipy and librosa\n",
            "< -  For text, either raw Python or Cython based loading, or NLTK and\n",
            "<    SpaCy are useful\n",
            "< \n",
            "< Specifically for vision, we have created a package called\n",
            "< ``torchvision``, that has data loaders for common datasets such as\n",
            "< Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
            "< ``torchvision.datasets`` and ``torch.utils.data.DataLoader``.\n",
            "< \n",
            "< This provides a huge convenience and avoids writing boilerplate code.\n",
            "< \n",
            "< For this tutorial, we will use the CIFAR10 dataset.\n",
            "< It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
            "< ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of\n",
            "< size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
            "---\n",
            "> import torch\n",
            "> import torchvision\n",
            "> import torchvision.transforms as transforms\n",
            "> import argparse\n",
            "> import deepspeed\n",
            "35,36d6\n",
            "< .. figure:: /_static/img/cifar10.png\n",
            "<    :alt: cifar10\n",
            "38c8\n",
            "<    cifar10\n",
            "---\n",
            "> def add_argument():\n",
            "39a10\n",
            ">     parser = argparse.ArgumentParser(description='CIFAR')\n",
            "41,42c12,93\n",
            "< Training an image classifier\n",
            "< ----------------------------\n",
            "---\n",
            ">     #data\n",
            ">     # cuda\n",
            ">     parser.add_argument('--with_cuda',\n",
            ">                         default=False,\n",
            ">                         action='store_true',\n",
            ">                         help='use CPU in case there\\'s no GPU support')\n",
            ">     parser.add_argument('--use_ema',\n",
            ">                         default=False,\n",
            ">                         action='store_true',\n",
            ">                         help='whether use exponential moving average')\n",
            "> \n",
            ">     # train\n",
            ">     parser.add_argument('-b',\n",
            ">                         '--batch_size',\n",
            ">                         default=32,\n",
            ">                         type=int,\n",
            ">                         help='mini-batch size (default: 32)')\n",
            ">     parser.add_argument('-e',\n",
            ">                         '--epochs',\n",
            ">                         default=30,\n",
            ">                         type=int,\n",
            ">                         help='number of total epochs (default: 30)')\n",
            ">     parser.add_argument('--local_rank',\n",
            ">                         type=int,\n",
            ">                         default=-1,\n",
            ">                         help='local rank passed from distributed launcher')\n",
            "> \n",
            ">     parser.add_argument('--log-interval',\n",
            ">                         type=int,\n",
            ">                         default=2000,\n",
            ">                         help=\"output logging information at a given interval\")\n",
            "> \n",
            ">     parser.add_argument('--moe',\n",
            ">                         default=False,\n",
            ">                         action='store_true',\n",
            ">                         help='use deepspeed mixture of experts (moe)')\n",
            "> \n",
            ">     parser.add_argument('--ep-world-size',\n",
            ">                         default=1,\n",
            ">                         type=int,\n",
            ">                         help='(moe) expert parallel world size')\n",
            ">     parser.add_argument('--num-experts',\n",
            ">                         type=int,\n",
            ">                         nargs='+',\n",
            ">                         default=[\n",
            ">                             1,\n",
            ">                         ],\n",
            ">                         help='number of experts list, MoE related.')\n",
            ">     parser.add_argument(\n",
            ">         '--mlp-type',\n",
            ">         type=str,\n",
            ">         default='standard',\n",
            ">         help=\n",
            ">         'Only applicable when num-experts > 1, accepts [standard, residual]')\n",
            ">     parser.add_argument('--top-k',\n",
            ">                         default=1,\n",
            ">                         type=int,\n",
            ">                         help='(moe) gating top 1 and 2 supported')\n",
            ">     parser.add_argument(\n",
            ">         '--min-capacity',\n",
            ">         default=0,\n",
            ">         type=int,\n",
            ">         help=\n",
            ">         '(moe) minimum capacity of an expert regardless of the capacity_factor'\n",
            ">     )\n",
            ">     parser.add_argument(\n",
            ">         '--noisy-gate-policy',\n",
            ">         default=None,\n",
            ">         type=str,\n",
            ">         help=\n",
            ">         '(moe) noisy gating (only supported with top-1). Valid values are None, RSample, and Jitter'\n",
            ">     )\n",
            ">     parser.add_argument(\n",
            ">         '--moe-param-group',\n",
            ">         default=False,\n",
            ">         action='store_true',\n",
            ">         help=\n",
            ">         '(moe) create separate moe param groups, required when using ZeRO w. MoE'\n",
            ">     )\n",
            "> \n",
            ">     # Include DeepSpeed configuration arguments\n",
            ">     parser = deepspeed.add_config_arguments(parser)\n",
            "44c95\n",
            "< We will do the following steps in order:\n",
            "---\n",
            ">     args = parser.parse_args()\n",
            "46,51c97\n",
            "< 1. Load and normalizing the CIFAR10 training and test datasets using\n",
            "<    ``torchvision``\n",
            "< 2. Define a Convolutional Neural Network\n",
            "< 3. Define a loss function\n",
            "< 4. Train the network on the training data\n",
            "< 5. Test the network on the test data\n",
            "---\n",
            ">     return args\n",
            "53,54d98\n",
            "< 1. Loading and normalizing CIFAR10\n",
            "< ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "56,60c100\n",
            "< Using ``torchvision``, it’s extremely easy to load CIFAR10.\n",
            "< \"\"\"\n",
            "< import torch\n",
            "< import torchvision\n",
            "< import torchvision.transforms as transforms\n",
            "---\n",
            "> deepspeed.init_distributed()\n",
            "73a114,117\n",
            "> if torch.distributed.get_rank() != 0:\n",
            ">     # might be downloading cifar data, let rank 0 download first\n",
            ">     torch.distributed.barrier()\n",
            "> \n",
            "77a122,126\n",
            "> \n",
            "> if torch.distributed.get_rank() == 0:\n",
            ">     # cifar data is downloaded, indicate other ranks can proceed\n",
            ">     torch.distributed.barrier()\n",
            "> \n",
            "79c128\n",
            "<                                           batch_size=4,\n",
            "---\n",
            ">                                           batch_size=16,\n",
            "113c162\n",
            "< images, labels = dataiter.next()\n",
            "---\n",
            "> images, labels = next(dataiter)\n",
            "128a178,179\n",
            "> args = add_argument()\n",
            "> \n",
            "138c189,207\n",
            "<         self.fc3 = nn.Linear(84, 10)\n",
            "---\n",
            ">         if args.moe:\n",
            ">             fc3 = nn.Linear(84, 84)\n",
            ">             self.moe_layer_list = []\n",
            ">             for n_e in args.num_experts:\n",
            ">                 # create moe layers based on the number of experts\n",
            ">                 self.moe_layer_list.append(\n",
            ">                     deepspeed.moe.layer.MoE(\n",
            ">                         hidden_size=84,\n",
            ">                         expert=fc3,\n",
            ">                         num_experts=n_e,\n",
            ">                         ep_size=args.ep_world_size,\n",
            ">                         use_residual=args.mlp_type == 'residual',\n",
            ">                         k=args.top_k,\n",
            ">                         min_capacity=args.min_capacity,\n",
            ">                         noisy_gate_policy=args.noisy_gate_policy))\n",
            ">             self.moe_layer_list = nn.ModuleList(self.moe_layer_list)\n",
            ">             self.fc4 = nn.Linear(84, 10)\n",
            ">         else:\n",
            ">             self.fc3 = nn.Linear(84, 10)\n",
            "146c215,220\n",
            "<         x = self.fc3(x)\n",
            "---\n",
            ">         if args.moe:\n",
            ">             for layer in self.moe_layer_list:\n",
            ">                 x, _, _ = layer(x)\n",
            ">             x = self.fc4(x)\n",
            ">         else:\n",
            ">             x = self.fc3(x)\n",
            "152,153d225\n",
            "< device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
            "< net.to(device)\n",
            "154a227,253\n",
            "> def create_moe_param_groups(model):\n",
            ">     from deepspeed.moe.utils import split_params_into_different_moe_groups_for_optimizer\n",
            "> \n",
            ">     parameters = {\n",
            ">         'params': [p for p in model.parameters()],\n",
            ">         'name': 'parameters'\n",
            ">     }\n",
            "> \n",
            ">     return split_params_into_different_moe_groups_for_optimizer(parameters)\n",
            "> \n",
            "> \n",
            "> parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
            "> if args.moe_param_group:\n",
            ">     parameters = create_moe_param_groups(net)\n",
            "> \n",
            "> # Initialize DeepSpeed to use the following features\n",
            "> # 1) Distributed model\n",
            "> # 2) Distributed data loader\n",
            "> # 3) DeepSpeed optimizer\n",
            "> model_engine, optimizer, trainloader, __ = deepspeed.initialize(\n",
            ">     args=args, model=net, model_parameters=parameters, training_data=trainset)\n",
            "> \n",
            "> fp16 = model_engine.fp16_enabled()\n",
            "> print(f'fp16={fp16}')\n",
            "> \n",
            "> #device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
            "> #net.to(device)\n",
            "163c262\n",
            "< optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
            "---\n",
            "> #optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
            "176c275\n",
            "<     for i, data in enumerate(trainloader, 0):\n",
            "---\n",
            ">     for i, data in enumerate(trainloader):\n",
            "178,185c277,281\n",
            "<         #inputs, labels = data\n",
            "<         inputs, labels = data[0].to(device), data[1].to(device)\n",
            "< \n",
            "<         # zero the parameter gradients\n",
            "<         optimizer.zero_grad()\n",
            "< \n",
            "<         # forward + backward + optimize\n",
            "<         outputs = net(inputs)\n",
            "---\n",
            ">         inputs, labels = data[0].to(model_engine.local_rank), data[1].to(\n",
            ">             model_engine.local_rank)\n",
            ">         if fp16:\n",
            ">             inputs = inputs.half()\n",
            ">         outputs = model_engine(inputs)\n",
            "187,188c283,285\n",
            "<         loss.backward()\n",
            "<         optimizer.step()\n",
            "---\n",
            "> \n",
            ">         model_engine.backward(loss)\n",
            ">         model_engine.step()\n",
            "192c289,291\n",
            "<         if i % 2000 == 1999:  # print every 2000 mini-batches\n",
            "---\n",
            ">         if i % args.log_interval == (\n",
            ">                 args.log_interval -\n",
            ">                 1):  # print every log_interval mini-batches\n",
            "194c293\n",
            "<                   (epoch + 1, i + 1, running_loss / 2000))\n",
            "---\n",
            ">                   (epoch + 1, i + 1, running_loss / args.log_interval))\n",
            "200,208d298\n",
            "< # Let's quickly save our trained model:\n",
            "< \n",
            "< PATH = './cifar_net.pth'\n",
            "< torch.save(net.state_dict(), PATH)\n",
            "< \n",
            "< ########################################################################\n",
            "< # See `here <https://pytorch.org/docs/stable/notes/serialization.html>`_\n",
            "< # for more details on saving PyTorch models.\n",
            "< #\n",
            "222c312\n",
            "< images, labels = dataiter.next()\n",
            "---\n",
            "> images, labels = next(dataiter)\n",
            "229,235d318\n",
            "< # Next, let's load back in our saved model (note: saving and re-loading the model\n",
            "< # wasn't necessary here, we only did it to illustrate how to do so):\n",
            "< \n",
            "< net = Net()\n",
            "< net.load_state_dict(torch.load(PATH))\n",
            "< \n",
            "< ########################################################################\n",
            "237,238c320,322\n",
            "< \n",
            "< outputs = net(images)\n",
            "---\n",
            "> if fp16:\n",
            ">     images = images.half()\n",
            "> outputs = net(images.to(model_engine.local_rank))\n",
            "259c343,345\n",
            "<         outputs = net(images)\n",
            "---\n",
            ">         if fp16:\n",
            ">             images = images.half()\n",
            ">         outputs = net(images.to(model_engine.local_rank))\n",
            "262c348,349\n",
            "<         correct += (predicted == labels).sum().item()\n",
            "---\n",
            ">         correct += (predicted == labels.to(\n",
            ">             model_engine.local_rank)).sum().item()\n",
            "280c367,369\n",
            "<         outputs = net(images)\n",
            "---\n",
            ">         if fp16:\n",
            ">             images = images.half()\n",
            ">         outputs = net(images.to(model_engine.local_rank))\n",
            "282c371\n",
            "<         c = (predicted == labels).squeeze()\n",
            "---\n",
            ">         c = (predicted == labels.to(model_engine.local_rank)).squeeze()\n",
            "291,368d379\n",
            "< \n",
            "< ########################################################################\n",
            "< # Okay, so what next?\n",
            "< #\n",
            "< # How do we run these neural networks on the GPU?\n",
            "< #\n",
            "< # Training on GPU\n",
            "< # ----------------\n",
            "< # Just like how you transfer a Tensor onto the GPU, you transfer the neural\n",
            "< # net onto the GPU.\n",
            "< #\n",
            "< # Let's first define our device as the first visible cuda device if we have\n",
            "< # CUDA available:\n",
            "< \n",
            "< device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
            "< \n",
            "< # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
            "< \n",
            "< print(device)\n",
            "< \n",
            "< ########################################################################\n",
            "< # The rest of this section assumes that ``device`` is a CUDA device.\n",
            "< #\n",
            "< # Then these methods will recursively go over all modules and convert their\n",
            "< # parameters and buffers to CUDA tensors:\n",
            "< #\n",
            "< # .. code:: python\n",
            "< #\n",
            "< #     net.to(device)\n",
            "< #\n",
            "< #\n",
            "< # Remember that you will have to send the inputs and targets at every step\n",
            "< # to the GPU too:\n",
            "< #\n",
            "< # .. code:: python\n",
            "< #\n",
            "< #         inputs, labels = data[0].to(device), data[1].to(device)\n",
            "< #\n",
            "< # Why dont I notice MASSIVE speedup compared to CPU? Because your network\n",
            "< # is really small.\n",
            "< #\n",
            "< # **Exercise:** Try increasing the width of your network (argument 2 of\n",
            "< # the first ``nn.Conv2d``, and argument 1 of the second ``nn.Conv2d`` –\n",
            "< # they need to be the same number), see what kind of speedup you get.\n",
            "< #\n",
            "< # **Goals achieved**:\n",
            "< #\n",
            "< # - Understanding PyTorch's Tensor library and neural networks at a high level.\n",
            "< # - Train a small neural network to classify images\n",
            "< #\n",
            "< # Training on multiple GPUs\n",
            "< # -------------------------\n",
            "< # If you want to see even more MASSIVE speedup using all of your GPUs,\n",
            "< # please check out :doc:`data_parallel_tutorial`.\n",
            "< #\n",
            "< # Where do I go next?\n",
            "< # -------------------\n",
            "< #\n",
            "< # -  :doc:`Train neural nets to play video games </intermediate/reinforcement_q_learning>`\n",
            "< # -  `Train a state-of-the-art ResNet network on imagenet`_\n",
            "< # -  `Train a face generator using Generative Adversarial Networks`_\n",
            "< # -  `Train a word-level language model using Recurrent LSTM networks`_\n",
            "< # -  `More examples`_\n",
            "< # -  `More tutorials`_\n",
            "< # -  `Discuss PyTorch on the Forums`_\n",
            "< # -  `Chat with other users on Slack`_\n",
            "< #\n",
            "< # .. _Train a state-of-the-art ResNet network on imagenet: https://github.com/pytorch/examples/tree/master/imagenet\n",
            "< # .. _Train a face generator using Generative Adversarial Networks: https://github.com/pytorch/examples/tree/master/dcgan\n",
            "< # .. _Train a word-level language model using Recurrent LSTM networks: https://github.com/pytorch/examples/tree/master/word_language_model\n",
            "< # .. _More examples: https://github.com/pytorch/examples\n",
            "< # .. _More tutorials: https://github.com/pytorch/tutorials\n",
            "< # .. _Discuss PyTorch on the Forums: https://discuss.pytorch.org/\n",
            "< # .. _Chat with other users on Slack: https://pytorch.slack.com/messages/beginner/\n",
            "< \n",
            "< # %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n",
            "< del dataiter\n",
            "< # %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n"
          ]
        }
      ]
    }
  ]
}