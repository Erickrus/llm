{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Erickrus/llm/blob/main/flowise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIQb_4GkME5a"
      },
      "source": [
        "https://www.youtube.com/watch?v=0B0oIs8NS9k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh41rdrSsHJB"
      },
      "source": [
        "##chatglm 6b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RUznzlAasPlr"
      },
      "outputs": [],
      "source": [
        "#@title clone ChatGLM2-6B repository\n",
        "!git clone https://github.com/THUDM/ChatGLM2-6B\n",
        "%cd /content/ChatGLM2-6B\n",
        "!pip3 install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fEgVvYZHsSWQ"
      },
      "outputs": [],
      "source": [
        "#@title clone pretrained model (chatglm-6b-int4) from huggingface\n",
        "!git clone https://huggingface.co/THUDM/chatglm2-6b-int4\n",
        "!cd chatglm2-6b-int4 && rm pytorch_model.bin\n",
        "#download it separately due to the git clone problem\n",
        "!cd chatglm2-6b-int4 && wget https://huggingface.co/THUDM/chatglm2-6b-int4/resolve/main/pytorch_model.bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "inyAlMy7sYOf"
      },
      "outputs": [],
      "source": [
        "#@title define FabUtil\n",
        "\n",
        "#@markdown FabUtil\n",
        "import os\n",
        "import json\n",
        "\n",
        "import tarfile\n",
        "from zipfile import ZipFile\n",
        "from google.colab._system_commands import _shell_line_magic as shell_line_magic\n",
        "\n",
        "\n",
        "class FabUtil:\n",
        "  def cust_code(self, codeFilename, content):\n",
        "    self._ensure_dir(codeFilename)\n",
        "    with open(codeFilename, 'w') as f:\n",
        "      f.write(content)\n",
        "\n",
        "  def fabricate(self, fabs):\n",
        "    # accept both filename and fabs object\n",
        "    if type(fabs) == str:\n",
        "      with open(fabs, \"r\") as f:\n",
        "        fabs = json.loads(fabs)\n",
        "    elif type(fabs) == dict:\n",
        "      pass\n",
        "\n",
        "    for i in range(len(fabs[\"fabs\"])):\n",
        "      fab = fabs[\"fabs\"][i]\n",
        "      if \"cmd\" in fab:\n",
        "        print(\"%s\" % fab[\"cmd\"])\n",
        "        shell_line_magic(\"%s\" % fab[\"cmd\"])\n",
        "        #os.system(\"%s\" % fab[\"cmd\"])\n",
        "        continue\n",
        "\n",
        "      if \"patches\" in fab:\n",
        "        self._patch(fab[\"srcFilename\"], fab[\"patches\"])\n",
        "        continue\n",
        "\n",
        "      entryFilename = \"\"\n",
        "      srcFilename = fab[\"srcFilename\"]\n",
        "      if srcFilename.find(\"::\") > 0:\n",
        "        srcFilename, entryFilename = srcFilename.split(\"::\")\n",
        "      tgtFilename = fab[\"tgtFilename\"]\n",
        "      srcFilename = os.path.join(fabs[\"baseDir\"], srcFilename)\n",
        "\n",
        "      if entryFilename != \"\":\n",
        "        self._process_zip_file(srcFilename, entryFilename, tgtFilename)\n",
        "      else:\n",
        "        self._ensure_dir(tgtFilename)\n",
        "        os.system(\"cp %s %s\" % (srcFilename, tgtFilename))\n",
        "        print(\"fabricated %s ==> %s\" % (srcFilename, tgtFilename))\n",
        "\n",
        "  def _patch(self, filename, patches):\n",
        "    changed = False\n",
        "    with open(filename, 'r') as f:\n",
        "      lines = f.read().split('\\n')\n",
        "    for patchItem in patches:\n",
        "      lineNum = patchItem['lineNum']\n",
        "      fromText = patchItem['fromText']\n",
        "      toText = patchItem['toText']\n",
        "      if lines[lineNum-1] == fromText:\n",
        "        lines[lineNum-1] = toText\n",
        "        changed = True\n",
        "    if changed:\n",
        "      with open(filename, 'w') as f:\n",
        "        f.write('\\n'.join(lines))\n",
        "\n",
        "  def _ensure_dir(self, tgtFilename):\n",
        "    dirName = os.path.dirname(tgtFilename)\n",
        "    if not os.path.exists(dirName):\n",
        "      os.system(\"mkdir -p %s \" % dirName)\n",
        "\n",
        "  def _process_zip_file(self, srcFilename, entryFilename, tgtFilename):\n",
        "    try:\n",
        "      if srcFilename.lower().find(\".tar\") > 0 or srcFilename.lower().find(\".tgz\") > 0:\n",
        "        fileOp = 'r'\n",
        "        if srcFilename.lower().endswith('.tar.gz') or srcFilename.lower().endswith('.tgz'): # gzip\n",
        "            fileOp = 'r:gz'\n",
        "        elif srcFilename.lower().endswith('.tar.bz2'): # bzip2\n",
        "            fileOp = 'r:bz2'\n",
        "        elif srcFilename.lower().endswith('.tar.xz'): # lzma\n",
        "            fileOp = 'r:xz'\n",
        "        with tarfile.open(srcFilename, fileOp) as tar:\n",
        "          self._ensure_dir(tgtFilename)\n",
        "          with open(tgtFilename, \"wb\") as f:\n",
        "            f.write(tar.extractfile(entryFilename).read())\n",
        "        print(\"fabricated %s::%s ==> %s\" % (srcFilename, entryFilename, tgtFilename))\n",
        "        return\n",
        "      if srcFilename.lower().find(\".zip\") >0:\n",
        "        with ZipFile(srcFilename, 'r') as z:\n",
        "          self._ensure_dir(tgtFilename)\n",
        "          with open(tgtFilename, \"wb\") as f:\n",
        "            f.write(z.read(entryFilename))\n",
        "        print(\"fabricated %s::%s ==> %s\" % (srcFilename, entryFilename, tgtFilename))\n",
        "        return\n",
        "    except:\n",
        "      print(\"failed %s::%s ==> %s\" % (srcFilename, entryFilename, tgtFilename))\n",
        "      return\n",
        "    print(\"not found %s::%s ==> %s\" % (srcFilename, entryFilename, tgtFilename))\n",
        "\n",
        "fb = FabUtil()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jyaheYtnsdDK"
      },
      "outputs": [],
      "source": [
        "#@title modify web_demo.py\n",
        "fb.fabricate({\n",
        "  \"baseDir\": \"/content/\",\n",
        "  \"fabs\": [\n",
        "    {\n",
        "        #@markdown modify tokenizer to load from ./chatglm-6b-int4\n",
        "        \"srcFilename\": \"web_demo.py\",\n",
        "        \"patches\": [{\n",
        "        \"lineNum\": 6,\n",
        "        \"fromText\": 'tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm2-6b\", trust_remote_code=True)',\n",
        "        \"toText\":   'tokenizer = AutoTokenizer.from_pretrained(\"./chatglm2-6b-int4\", trust_remote_code=True)',\n",
        "        }]\n",
        "    },\n",
        "    {\n",
        "        #@markdown modify model to load from ./chatglm-6b-int4\n",
        "        \"srcFilename\": \"web_demo.py\",\n",
        "        \"patches\": [{\n",
        "        \"lineNum\": 7,\n",
        "        \"fromText\": 'model = AutoModel.from_pretrained(\"THUDM/chatglm2-6b\", trust_remote_code=True).cuda()',\n",
        "        \"toText\":   'model = AutoModel.from_pretrained(\"./chatglm2-6b-int4\", trust_remote_code=True).half().cuda()',\n",
        "        }]\n",
        "    },\n",
        "    {\n",
        "        #@markdown To create a public link, set `share=True` in `launch()`.\n",
        "        \"srcFilename\": \"web_demo.py\",\n",
        "        \"patches\": [{\n",
        "        \"lineNum\": 108,\n",
        "        \"fromText\": 'demo.queue().launch(share=False, inbrowser=True)',\n",
        "        \"toText\":   'demo.queue().launch(share=True, inbrowser=True)',\n",
        "        }]\n",
        "    },\n",
        "    {\n",
        "        #@markdown print(input)\n",
        "        \"srcFilename\": \"web_demo.py\",\n",
        "        \"patches\": [{\n",
        "        \"lineNum\": 63,\n",
        "        \"fromText\": 'def predict(input, chatbot, max_length, top_p, temperature, history, past_key_values):',\n",
        "        \"toText\":   'def predict(input, chatbot, max_length, top_p, temperature, history, past_key_values):\\n    print(input)',\n",
        "        }]\n",
        "    }\n",
        "  ]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4ti-rKdsl_Y",
        "outputId": "a574417b-8e43-4fe0-874a-d37a35c896ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/ChatGLM2-6B/web_demo.py:91: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
            "  user_input = gr.Textbox(show_label=False, placeholder=\"Input...\", lines=10).style(\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://697006c05b4ac8e9ea.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "hi\n",
            "hi\n",
            "2023-10-17 03:57:14.945714: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "#@title start web_demo\n",
        "!python3 web_demo.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHOTwX5dsAbn"
      },
      "source": [
        "##cpolar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfHzjlrchclf",
        "outputId": "cf634246-2283-4997-e88f-bac41df34d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-07 04:20:50--  https://static.cpolar.com/downloads/releases/3.3.18/cpolar-stable-linux-amd64.zip?_gl=1*37bbhq*_ga*MTcyNDU3NzMyNC4xNjk3NTEwNjQw*_ga_WF16DPKZZ1*MTY5NzUxMDYzOS4xLjEuMTY5NzUxMDY2MS4zOC4wLjA.\n",
            "Resolving static.cpolar.com (static.cpolar.com)... 47.246.24.237, 2404:2280:1b2:0:3::3fe\n",
            "Connecting to static.cpolar.com (static.cpolar.com)|47.246.24.237|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7423434 (7.1M) [application/zip]\n",
            "Saving to: ‘cpolar-stable-linux-amd64.zip?_gl=1*37bbhq*_ga*MTcyNDU3NzMyNC4xNjk3NTEwNjQw*_ga_WF16DPKZZ1*MTY5NzUxMDYzOS4xLjEuMTY5NzUxMDY2MS4zOC4wLjA.’\n",
            "\n",
            "cpolar-stable-linux 100%[===================>]   7.08M   248KB/s    in 31s     \n",
            "\n",
            "2024-05-07 04:21:20 (236 KB/s) - ‘cpolar-stable-linux-amd64.zip?_gl=1*37bbhq*_ga*MTcyNDU3NzMyNC4xNjk3NTEwNjQw*_ga_WF16DPKZZ1*MTY5NzUxMDYzOS4xLjEuMTY5NzUxMDY2MS4zOC4wLjA.’ saved [7423434/7423434]\n",
            "\n",
            "Archive:  /content/cpolar-stable-linux-amd64.zip\n",
            "  inflating: cpolar                  \n",
            "Authtoken saved to configuration file: /root/.cpolar/cpolar.yml\n"
          ]
        }
      ],
      "source": [
        "#@title install cpolar\n",
        "\n",
        "!wget https://static.cpolar.com/downloads/releases/3.3.18/cpolar-stable-linux-amd64.zip?_gl=1*37bbhq*_ga*MTcyNDU3NzMyNC4xNjk3NTEwNjQw*_ga_WF16DPKZZ1*MTY5NzUxMDYzOS4xLjEuMTY5NzUxMDY2MS4zOC4wLjA.\n",
        "!mv /content/cpolar* /content/cpolar-stable-linux-amd64.zip\n",
        "!unzip /content/cpolar-stable-linux-amd64.zip\n",
        "!./cpolar authtoken ......\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwFPQd7RiNhm",
        "outputId": "e8a3ecdd-7a34-49ff-e34e-93aaa1a72e10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            "root        3829       1  0 04:21 ?        00:00:00 cpolar: master procSHELL=/bin/bash\n",
            "root        3837     194  0 04:21 ?        00:00:00 /bin/bash -c sleep 5 && ps -ef | grep cpolar\n",
            "root        3860    3837  0 04:21 ?        00:00:00 grep cpolar\n"
          ]
        }
      ],
      "source": [
        "#@title start cpolar\n",
        "\n",
        "!nohup ./cpolar http 3000 &\n",
        "#!while true;do clear; ps -ef | grep cpolar ; sleep 5; done\n",
        "\n",
        "!sleep 5 && ps -ef | grep cpolar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdtE0fKisDVz"
      },
      "source": [
        "## flowise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rbYyg_BgAFE",
        "outputId": "0c219f65-b52c-4d2e-b6f5-38964a364a5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\n",
            "added 2661 packages in 6m\n",
            "\n",
            "293 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m \n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m New \u001b[33mminor\u001b[39m version of npm available! \u001b[31m10.5.0\u001b[39m -> \u001b[32m10.7.0\u001b[39m\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m Changelog: \u001b[36mhttps://github.com/npm/cli/releases/tag/v10.7.0\u001b[39m\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m Run \u001b[32mnpm install -g npm@10.7.0\u001b[39m to update!\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m \n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#@title install flowise\n",
        "!curl -sL https://deb.nodesource.com/setup_20.x | sudo -E bash -\n",
        "!apt-get install -y nodejs\n",
        "!npm install -g flowise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRhYcEJYhw_m",
        "outputId": "4311aef5-1256-4c9c-bdf3-12fe25dfa98e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ],
      "source": [
        "#@title start flowise\n",
        "!nohup npx flowise start &"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpS0j-4CUkQY",
        "outputId": "74162cc8-5984-4c5e-cff1-ecd15c0797c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!curl -fsSL https://ollama.com/install.sh | sh\n",
        "!nohup ollama serve &\n",
        "#!ollama run phi3"
      ],
      "metadata": {
        "id": "9-cDfN-aUDdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ollama serve &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoU9GlbbU9_O",
        "outputId": "c63fe46b-4762-433d-c7aa-cddce7cabb9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time=2024-05-07T04:38:20.032Z level=INFO source=images.go:828 msg=\"total blobs: 5\"\n",
            "time=2024-05-07T04:38:20.039Z level=INFO source=images.go:835 msg=\"total unused blobs removed: 0\"\n",
            "time=2024-05-07T04:38:20.039Z level=INFO source=routes.go:1071 msg=\"Listening on 127.0.0.1:11434 (version 0.1.33)\"\n",
            "time=2024-05-07T04:38:20.040Z level=INFO source=payload.go:30 msg=\"extracting embedded files\" dir=/tmp/ollama433625851/runners\n",
            "time=2024-05-07T04:38:33.393Z level=INFO source=payload.go:44 msg=\"Dynamic LLM libraries [cpu cpu_avx cpu_avx2 cuda_v11 rocm_v60002]\"\n",
            "time=2024-05-07T04:38:33.393Z level=INFO source=gpu.go:96 msg=\"Detecting GPUs\"\n",
            "time=2024-05-07T04:38:33.406Z level=INFO source=cpu_common.go:11 msg=\"CPU has AVX2\"\n",
            "time=2024-05-07T04:38:33.407Z level=INFO source=gpu.go:96 msg=\"Detecting GPUs\"\n",
            "time=2024-05-07T04:38:33.415Z level=INFO source=cpu_common.go:11 msg=\"CPU has AVX2\"\n",
            "time=2024-05-07T04:38:33.807Z level=INFO source=cpu_common.go:11 msg=\"CPU has AVX2\"\n",
            "time=2024-05-07T04:38:33.813Z level=INFO source=server.go:289 msg=\"starting llama server\" cmd=\"/tmp/ollama433625851/runners/cpu_avx2/ollama_llama_server --model /root/.ollama/models/blobs/sha256-4fed7364ee3e0c7cb4fe0880148bfdfcd1b630981efa0802a6b62ee52e7da97e --ctx-size 2048 --batch-size 512 --embedding --log-disable --parallel 1 --port 41127\"\n",
            "time=2024-05-07T04:38:33.822Z level=INFO source=sched.go:340 msg=\"loaded runners\" count=1\n",
            "time=2024-05-07T04:38:33.822Z level=INFO source=server.go:432 msg=\"waiting for llama runner to start responding\"\n",
            "{\"function\":\"server_params_parse\",\"level\":\"INFO\",\"line\":2606,\"msg\":\"logging to file is disabled.\",\"tid\":\"137518671935360\",\"timestamp\":1715056713}\n",
            "{\"build\":1,\"commit\":\"952d03d\",\"function\":\"main\",\"level\":\"INFO\",\"line\":2822,\"msg\":\"build info\",\"tid\":\"137518671935360\",\"timestamp\":1715056713}\n",
            "{\"function\":\"main\",\"level\":\"INFO\",\"line\":2825,\"msg\":\"system info\",\"n_threads\":2,\"n_threads_batch\":-1,\"system_info\":\"AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \",\"tid\":\"137518671935360\",\"timestamp\":1715056713,\"total_threads\":2}\n",
            "llama_model_loader: loaded meta data with 25 key-value pairs and 291 tensors from /root/.ollama/models/blobs/sha256-4fed7364ee3e0c7cb4fe0880148bfdfcd1b630981efa0802a6b62ee52e7da97e (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                           llama.vocab_size u32              = 32064\n",
            "llama_model_loader: - kv   3:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 3072\n",
            "llama_model_loader: - kv   5:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   6:                  llama.feed_forward_length u32              = 8192\n",
            "llama_model_loader: - kv   7:                 llama.rope.dimension_count u32              = 96\n",
            "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv  10:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  12:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,32064]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.scores arr[f32,32064]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,32064]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 32000\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 32000\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  22:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
            "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 323/32064 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32064\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 3072\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 96\n",
            "llm_load_print_meta: n_embd_head_k    = 96\n",
            "llm_load_print_meta: n_embd_head_v    = 96\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 3072\n",
            "llm_load_print_meta: n_embd_v_gqa     = 3072\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 8192\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 3.82 B\n",
            "llm_load_print_meta: model size       = 2.16 GiB (4.85 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 32000 '<|endoftext|>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: PAD token        = 32000 '<|endoftext|>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_print_meta: EOT token        = 32007 '<|end|>'\n",
            "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
            "llm_load_tensors:        CPU buffer size =  2210.78 MiB\n",
            ".................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 2048\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   768.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  768.00 MiB, K (f16):  384.00 MiB, V (f16):  384.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.13 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =   156.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "{\"function\":\"initialize\",\"level\":\"INFO\",\"line\":448,\"msg\":\"initializing slots\",\"n_slots\":1,\"tid\":\"137518671935360\",\"timestamp\":1715056721}\n",
            "{\"function\":\"initialize\",\"level\":\"INFO\",\"line\":457,\"msg\":\"new slot\",\"n_ctx_slot\":2048,\"slot_id\":0,\"tid\":\"137518671935360\",\"timestamp\":1715056721}\n",
            "{\"function\":\"main\",\"level\":\"INFO\",\"line\":3067,\"msg\":\"model loaded\",\"tid\":\"137518671935360\",\"timestamp\":1715056721}\n",
            "{\"function\":\"main\",\"hostname\":\"127.0.0.1\",\"level\":\"INFO\",\"line\":3270,\"msg\":\"HTTP server listening\",\"n_threads_http\":\"3\",\"port\":\"41127\",\"tid\":\"137518671935360\",\"timestamp\":1715056721}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1581,\"msg\":\"all slots are idle and system prompt is empty, clear the KV cache\",\"tid\":\"137518671935360\",\"timestamp\":1715056721}\n",
            "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1509,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":0,\"tid\":\"137518671935360\",\"timestamp\":1715056721}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":53454,\"status\":200,\"tid\":\"137515336332864\",\"timestamp\":1715056721}\n",
            "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1509,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":1,\"tid\":\"137518671935360\",\"timestamp\":1715056721}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":53470,\"status\":200,\"tid\":\"137515336332864\",\"timestamp\":1715056721}\n",
            "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1509,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":2,\"tid\":\"137518671935360\",\"timestamp\":1715056721}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":53478,\"status\":200,\"tid\":\"137515344725568\",\"timestamp\":1715056721}\n",
            "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1509,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":3,\"tid\":\"137518671935360\",\"timestamp\":1715056721}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":53494,\"status\":200,\"tid\":\"137515336332864\",\"timestamp\":1715056721}\n",
            "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1509,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":4,\"tid\":\"137518671935360\",\"timestamp\":1715056721}\n",
            "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1509,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":5,\"tid\":\"137518671935360\",\"timestamp\":1715056721}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":53502,\"status\":200,\"tid\":\"137515344725568\",\"timestamp\":1715056721}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":53500,\"status\":200,\"tid\":\"137515336332864\",\"timestamp\":1715056721}\n",
            "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1509,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":6,\"tid\":\"137518671935360\",\"timestamp\":1715056721}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":59972,\"status\":200,\"tid\":\"137515344725568\",\"timestamp\":1715056721}\n",
            "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1509,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":7,\"tid\":\"137518671935360\",\"timestamp\":1715056721}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":59972,\"status\":200,\"tid\":\"137515344725568\",\"timestamp\":1715056721}\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":8,\"tid\":\"137518671935360\",\"timestamp\":1715056721}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1812,\"msg\":\"slot progression\",\"n_past\":0,\"n_past_se\":0,\"n_prompt_tokens_processed\":42,\"slot_id\":0,\"task_id\":8,\"tid\":\"137518671935360\",\"timestamp\":1715056721}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1839,\"msg\":\"kv cache rm [p0, end)\",\"p0\":0,\"slot_id\":0,\"task_id\":8,\"tid\":\"137518671935360\",\"timestamp\":1715056721}\n",
            "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1509,\"msg\":\"slot data\",\"n_idle_slots\":0,\"n_processing_slots\":1,\"task_id\":20,\"tid\":\"137518671935360\",\"timestamp\":1715056747}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":42448,\"status\":200,\"tid\":\"137515336332864\",\"timestamp\":1715056747}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":269,\"msg\":\"prompt eval time     =   11170.16 ms /    42 tokens (  265.96 ms per token,     3.76 tokens per second)\",\"n_prompt_tokens_processed\":42,\"n_tokens_second\":3.760017424995038,\"slot_id\":0,\"t_prompt_processing\":11170.161,\"t_token\":265.9562142857143,\"task_id\":8,\"tid\":\"137518671935360\",\"timestamp\":1715056756}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":283,\"msg\":\"generation eval time =   23612.10 ms /    25 runs   (  944.48 ms per token,     1.06 tokens per second)\",\"n_decoded\":25,\"n_tokens_second\":1.0587790058861337,\"slot_id\":0,\"t_token\":944.48416,\"t_token_generation\":23612.104,\"task_id\":8,\"tid\":\"137518671935360\",\"timestamp\":1715056756}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":293,\"msg\":\"          total time =   34782.26 ms\",\"slot_id\":0,\"t_prompt_processing\":11170.161,\"t_token_generation\":23612.104,\"t_total\":34782.265,\"task_id\":8,\"tid\":\"137518671935360\",\"timestamp\":1715056756}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"POST\",\"msg\":\"request\",\"params\":{},\"path\":\"/completion\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":59972,\"status\":200,\"tid\":\"137515344725568\",\"timestamp\":1715056756}\n",
            "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1509,\"msg\":\"slot data\",\"n_idle_slots\":0,\"n_processing_slots\":1,\"task_id\":36,\"tid\":\"137518671935360\",\"timestamp\":1715056756}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":59972,\"status\":200,\"tid\":\"137515344725568\",\"timestamp\":1715056756}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1643,\"msg\":\"slot released\",\"n_cache_tokens\":67,\"n_ctx\":2048,\"n_past\":66,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":8,\"tid\":\"137518671935360\",\"timestamp\":1715056756,\"truncated\":false}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"POST\",\"msg\":\"request\",\"params\":{},\"path\":\"/tokenize\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":59972,\"status\":200,\"tid\":\"137515344725568\",\"timestamp\":1715056756}\n",
            "[GIN] 2024/05/07 - 04:39:16 |\u001b[97;42m 200 \u001b[0m| 42.984163653s |       127.0.0.1 |\u001b[97;46m POST    \u001b[0m \"/api/generate\"\n",
            "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1509,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":38,\"tid\":\"137518671935360\",\"timestamp\":1715056756}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":59188,\"status\":200,\"tid\":\"137515353118272\",\"timestamp\":1715056756}\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":39,\"tid\":\"137518671935360\",\"timestamp\":1715056756}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1812,\"msg\":\"slot progression\",\"n_past\":15,\"n_past_se\":0,\"n_prompt_tokens_processed\":20,\"slot_id\":0,\"task_id\":39,\"tid\":\"137518671935360\",\"timestamp\":1715056756}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1839,\"msg\":\"kv cache rm [p0, end)\",\"p0\":15,\"slot_id\":0,\"task_id\":39,\"tid\":\"137518671935360\",\"timestamp\":1715056756}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":269,\"msg\":\"prompt eval time     =    9960.11 ms /    20 tokens (  498.01 ms per token,     2.01 tokens per second)\",\"n_prompt_tokens_processed\":20,\"n_tokens_second\":2.0080091452768514,\"slot_id\":0,\"t_prompt_processing\":9960.114,\"t_token\":498.0057,\"task_id\":39,\"tid\":\"137518671935360\",\"timestamp\":1715056778}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":283,\"msg\":\"generation eval time =   12530.86 ms /    15 runs   (  835.39 ms per token,     1.20 tokens per second)\",\"n_decoded\":15,\"n_tokens_second\":1.1970449270113825,\"slot_id\":0,\"t_token\":835.3905333333333,\"t_token_generation\":12530.858,\"task_id\":39,\"tid\":\"137518671935360\",\"timestamp\":1715056778}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":293,\"msg\":\"          total time =   22490.97 ms\",\"slot_id\":0,\"t_prompt_processing\":9960.114,\"t_token_generation\":12530.858,\"t_total\":22490.972,\"task_id\":39,\"tid\":\"137518671935360\",\"timestamp\":1715056778}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"POST\",\"msg\":\"request\",\"params\":{},\"path\":\"/completion\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":59188,\"status\":200,\"tid\":\"137515353118272\",\"timestamp\":1715056778}\n",
            "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1509,\"msg\":\"slot data\",\"n_idle_slots\":0,\"n_processing_slots\":1,\"task_id\":56,\"tid\":\"137518671935360\",\"timestamp\":1715056778}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":59188,\"status\":200,\"tid\":\"137515353118272\",\"timestamp\":1715056778}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1643,\"msg\":\"slot released\",\"n_cache_tokens\":50,\"n_ctx\":2048,\"n_past\":49,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":39,\"tid\":\"137518671935360\",\"timestamp\":1715056778,\"truncated\":false}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"POST\",\"msg\":\"request\",\"params\":{},\"path\":\"/tokenize\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":59188,\"status\":200,\"tid\":\"137515353118272\",\"timestamp\":1715056778}\n",
            "[GIN] 2024/05/07 - 04:39:38 |\u001b[97;42m 200 \u001b[0m| 32.797214872s |       127.0.0.1 |\u001b[97;46m POST    \u001b[0m \"/api/generate\"\n",
            "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1509,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":58,\"tid\":\"137518671935360\",\"timestamp\":1715056812}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":48844,\"status\":200,\"tid\":\"137515336332864\",\"timestamp\":1715056812}\n",
            "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1509,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":59,\"tid\":\"137518671935360\",\"timestamp\":1715056812}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":48844,\"status\":200,\"tid\":\"137515336332864\",\"timestamp\":1715056812}\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":60,\"tid\":\"137518671935360\",\"timestamp\":1715056812}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1812,\"msg\":\"slot progression\",\"n_past\":15,\"n_past_se\":0,\"n_prompt_tokens_processed\":25,\"slot_id\":0,\"task_id\":60,\"tid\":\"137518671935360\",\"timestamp\":1715056812}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1839,\"msg\":\"kv cache rm [p0, end)\",\"p0\":15,\"slot_id\":0,\"task_id\":60,\"tid\":\"137518671935360\",\"timestamp\":1715056812}\n",
            "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1509,\"msg\":\"slot data\",\"n_idle_slots\":0,\"n_processing_slots\":1,\"task_id\":116,\"tid\":\"137518671935360\",\"timestamp\":1715056846}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":43092,\"status\":200,\"tid\":\"137515344725568\",\"timestamp\":1715056846}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":269,\"msg\":\"prompt eval time     =    9703.24 ms /    25 tokens (  388.13 ms per token,     2.58 tokens per second)\",\"n_prompt_tokens_processed\":25,\"n_tokens_second\":2.5764582006242653,\"slot_id\":0,\"t_prompt_processing\":9703.243,\"t_token\":388.12972,\"task_id\":60,\"tid\":\"137518671935360\",\"timestamp\":1715056885}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":283,\"msg\":\"generation eval time =   63236.57 ms /   116 runs   (  545.14 ms per token,     1.83 tokens per second)\",\"n_decoded\":116,\"n_tokens_second\":1.83438150577831,\"slot_id\":0,\"t_token\":545.1428706896552,\"t_token_generation\":63236.573,\"task_id\":60,\"tid\":\"137518671935360\",\"timestamp\":1715056885}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":293,\"msg\":\"          total time =   72939.82 ms\",\"slot_id\":0,\"t_prompt_processing\":9703.243,\"t_token_generation\":63236.573,\"t_total\":72939.81599999999,\"task_id\":60,\"tid\":\"137518671935360\",\"timestamp\":1715056885}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"POST\",\"msg\":\"request\",\"params\":{},\"path\":\"/completion\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":48844,\"status\":200,\"tid\":\"137515336332864\",\"timestamp\":1715056885}\n",
            "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1509,\"msg\":\"slot data\",\"n_idle_slots\":0,\"n_processing_slots\":1,\"task_id\":179,\"tid\":\"137518671935360\",\"timestamp\":1715056885}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":48844,\"status\":200,\"tid\":\"137515336332864\",\"timestamp\":1715056885}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1643,\"msg\":\"slot released\",\"n_cache_tokens\":156,\"n_ctx\":2048,\"n_past\":155,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":60,\"tid\":\"137518671935360\",\"timestamp\":1715056885,\"truncated\":false}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"POST\",\"msg\":\"request\",\"params\":{},\"path\":\"/tokenize\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":48844,\"status\":200,\"tid\":\"137515336332864\",\"timestamp\":1715056885}\n",
            "[GIN] 2024/05/07 - 04:41:25 |\u001b[97;42m 200 \u001b[0m|         1m13s |       127.0.0.1 |\u001b[97;46m POST    \u001b[0m \"/api/generate\"\n",
            "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1509,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":181,\"tid\":\"137518671935360\",\"timestamp\":1715056885}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":45160,\"status\":200,\"tid\":\"137515336332864\",\"timestamp\":1715056885}\n",
            "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":182,\"tid\":\"137518671935360\",\"timestamp\":1715056885}\n",
            "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1812,\"msg\":\"slot progression\",\"n_past\":40,\"n_past_se\":0,\"n_prompt_tokens_processed\":0,\"slot_id\":0,\"task_id\":182,\"tid\":\"137518671935360\",\"timestamp\":1715056885}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1827,\"msg\":\"we have to evaluate at least 1 token to generate logits\",\"slot_id\":0,\"task_id\":182,\"tid\":\"137518671935360\",\"timestamp\":1715056885}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1839,\"msg\":\"kv cache rm [p0, end)\",\"p0\":39,\"slot_id\":0,\"task_id\":182,\"tid\":\"137518671935360\",\"timestamp\":1715056885}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":269,\"msg\":\"prompt eval time     =     366.15 ms /     0 tokens (     inf ms per token,     0.00 tokens per second)\",\"n_prompt_tokens_processed\":0,\"n_tokens_second\":0.0,\"slot_id\":0,\"t_prompt_processing\":366.154,\"t_token\":null,\"task_id\":182,\"tid\":\"137518671935360\",\"timestamp\":1715056900}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":283,\"msg\":\"generation eval time =   15022.96 ms /    20 runs   (  751.15 ms per token,     1.33 tokens per second)\",\"n_decoded\":20,\"n_tokens_second\":1.3312959180603336,\"slot_id\":0,\"t_token\":751.1478,\"t_token_generation\":15022.956,\"task_id\":182,\"tid\":\"137518671935360\",\"timestamp\":1715056900}\n",
            "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":293,\"msg\":\"          total time =   15389.11 ms\",\"slot_id\":0,\"t_prompt_processing\":366.154,\"t_token_generation\":15022.956,\"t_total\":15389.11,\"task_id\":182,\"tid\":\"137518671935360\",\"timestamp\":1715056900}\n",
            "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1643,\"msg\":\"slot released\",\"n_cache_tokens\":60,\"n_ctx\":2048,\"n_past\":59,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":182,\"tid\":\"137518671935360\",\"timestamp\":1715056900,\"truncated\":false}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"POST\",\"msg\":\"request\",\"params\":{},\"path\":\"/completion\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":45160,\"status\":200,\"tid\":\"137515336332864\",\"timestamp\":1715056900}\n",
            "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1509,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":205,\"tid\":\"137518671935360\",\"timestamp\":1715056900}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":45160,\"status\":200,\"tid\":\"137515336332864\",\"timestamp\":1715056900}\n",
            "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2737,\"method\":\"POST\",\"msg\":\"request\",\"params\":{},\"path\":\"/tokenize\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":45160,\"status\":200,\"tid\":\"137515336332864\",\"timestamp\":1715056900}\n",
            "[GIN] 2024/05/07 - 04:41:40 |\u001b[97;42m 200 \u001b[0m| 54.656042546s |       127.0.0.1 |\u001b[97;46m POST    \u001b[0m \"/api/generate\"\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "sh41rdrSsHJB",
        "cHOTwX5dsAbn",
        "pdtE0fKisDVz"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyP5OxPGr+YCDVM9YFGQMjEN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}