{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Erickrus/llm/blob/main/AI_Paper_Highlighter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBTD4iGO2tNK"
      },
      "source": [
        "# AI Paper Highlighter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "CUXBepKGwBIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a664e2c1-ba40-45c3-9cef-d57eb0f731b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m342.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126281 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.8_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m459.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#@title installations\n",
        "!pip install -q PyPDF2 pdfplumber pymupdf\n",
        "!apt-get -qq update -y\n",
        "!apt-get install -y -qq poppler-utils\n",
        "!pip3 -q install pdf2image\n",
        "!pip3 install -q -U langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title setup GOOGLE_API_KEY\n",
        "#@markdown Gemini Flash 2.5 is used to generate the highlight\n",
        "import getpass\n",
        "import os\n",
        "GOOGLE_API_KEY = getpass.getpass(\"Enter your GOOGLE_API_KEY: \")\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI5oQm5nloY4",
        "outputId": "354e6c97-1a77-4e12-bea1-99b4afc35bf6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your GOOGLE_API_KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH2MzwzW1TV_",
        "outputId": "037e4020-7715-4137-f31f-035827fd9d2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FILE_NAME: 2507.02259v1.pdf\n",
            "HTML_FILENAME: 2507.02259v1.html\n",
            "PDF_FILENAME: 2507.02259v1.pdf\n",
            "HTML_OUT_FILENAME: 2507.02259v1_out.html\n",
            "PDF_OUT_FILENAME: 2507.02259v1_out.pdf\n",
            "extracted text from https://arxiv.org/html/2507.02259\n",
            "invoke LLM to higlight paper text\n",
            "highlighted 2507.02259v1.html is saved\n",
            "Conversion complete! Output saved to 2507.02259v1_out.html\n",
            "Warning: Could not find match for 'performance degradation and slow processing speed due to O(n^2) computational complexity' in PDF. Skipping.\n",
            "Warning: Could not find match for 'O(C+M)' in PDF. Skipping.\n",
            "Warning: Could not find match for 'back-propagation alone cannot teach the model what to keep and what to discard' in PDF. Skipping.\n",
            "Warning: Could not find match for 'MemAgent-14B achieves over 95% accuracy on the average RULER tasks in context ranging from 8K to 512K' in PDF. Skipping.\n",
            "Warning: Could not find match for 'O(n^2) complexity' in PDF. Skipping.\n",
            "PDF with highlights is saved to 2507.02259v1_out.pdf\n"
          ]
        }
      ],
      "source": [
        "#@title highlight paper\n",
        "\n",
        "import os\n",
        "import requests\n",
        "\n",
        "\n",
        "PAPER_NAME = \"2507.02259\" #@param {type:\"string\"}\n",
        "\n",
        "# download pdf file directly from https://arxiv.org/html/2410.01943 and save the pdf\n",
        "url = f'https://arxiv.org/pdf/{PAPER_NAME}'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "# the name will be changed, how to get the name from arxiv?\n",
        "FILE_NAME = r.headers['Content-Disposition'].split('filename=')[1]\n",
        "FILE_NAME= FILE_NAME.strip('\"')\n",
        "open(FILE_NAME, 'wb').write(r.content)\n",
        "print(f\"FILE_NAME: {FILE_NAME}\")\n",
        "\n",
        "# FILE_NAME = \"2410.01943v1.pdf\" #@param {type:\"string\"}\n",
        "\n",
        "HTML_FILENAME = FILE_NAME[:-4] + \".html\"\n",
        "PDF_FILENAME = FILE_NAME[:-4] + \".pdf\"\n",
        "HTML_OUT_FILENAME = FILE_NAME[:-4] + \"_out.html\"\n",
        "PDF_OUT_FILENAME = FILE_NAME[:-4] + \"_out.pdf\"\n",
        "\n",
        "\n",
        "print(f\"HTML_FILENAME: {HTML_FILENAME}\")\n",
        "print(f\"PDF_FILENAME: {PDF_FILENAME}\")\n",
        "print(f\"HTML_OUT_FILENAME: {HTML_OUT_FILENAME}\")\n",
        "print(f\"PDF_OUT_FILENAME: {PDF_OUT_FILENAME}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "url = f\"https://arxiv.org/html/{PAPER_NAME}\"\n",
        "response = requests.get(url)\n",
        "html_content = response.content.decode('utf-8')\n",
        "\n",
        "# use beautiful soup to extract texts under <article> tag, however, will not include the section where class='ltx_bibliography'\n",
        "# which means everything under and include this section will not be included in the extract texts.\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Find the article tag\n",
        "article_tag = soup.find('article')\n",
        "\n",
        "extracted_text = \"\"\n",
        "if article_tag:\n",
        "    # Remove the bibliography section if it exists within the article\n",
        "    bibliography_section = article_tag.find(class_='ltx_bibliography')\n",
        "    if bibliography_section:\n",
        "        bibliography_section.extract()\n",
        "\n",
        "    # Extract all text from the article tag\n",
        "    extracted_text = article_tag.get_text(separator='\\n')\n",
        "    #print(extracted_text)\n",
        "    print(f\"extracted text from {url}\")\n",
        "\n",
        "print(\"invoke LLM to higlight paper text\")\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")\n",
        "\n",
        "PROMPT = f'''This is the entire paper in text:\n",
        "Now can you mark the highlight tag for this paper ? highlight means something important in the key paragraph , they are key sentence or key phrase or words. using <highlight>...</highlight> to wrap them up. Make sure highlight is not the entire paragraph.\n",
        "https://arxiv.org/html/{PAPER_NAME}\n",
        "\n",
        "```\n",
        "{extracted_text}\n",
        "```\n",
        "'''\n",
        "response = llm.invoke(PROMPT)\n",
        "\n",
        "with open(HTML_FILENAME, \"w\") as f:\n",
        "    content = response.content.replace(\"<highlight>\", \"&lt;highlight&gt;\").replace(\"</highlight>\", \"&lt;/highlight&gt;\").replace(\"\\n\", \"<br/>\")\n",
        "    f.write(f\"\"\"<html><body><pre>{content}</pre></body></html>\"\"\")\n",
        "    print(f\"highlighted {HTML_FILENAME} is saved\")\n",
        "\n",
        "\n",
        "with open('/content/highlight.py', 'w') as f:\n",
        "    f.write('''def convert_highlights(input_file, output_file):\n",
        "    try:\n",
        "        # Read the input HTML file\n",
        "        with open(input_file, 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "\n",
        "        # Replace <highlight> tags with span tags containing yellow background style\n",
        "        converted_content = content.replace(\n",
        "            '&lt;highlight&gt;',\n",
        "            '<span style=\"background-color: yellow;\">'\n",
        "        ).replace(\n",
        "            '&lt;/highlight&gt;',\n",
        "            '</span>'\n",
        "        )\n",
        "\n",
        "        # Write the converted content to output file\n",
        "        with open(output_file, 'w', encoding='utf-8') as file:\n",
        "            file.write(converted_content)\n",
        "\n",
        "        print(f\"Conversion complete! Output saved to {output_file}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file '{input_file}' not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    import os,sys\n",
        "    input_html = sys.argv[1]\n",
        "    output_html = sys.argv[2]\n",
        "    convert_highlights(input_html, output_html)\n",
        "''')\n",
        "\n",
        "with open(\"/content/highlight_pdf.py\", \"w\") as f:\n",
        "    f.write('''\n",
        "import re\n",
        "import fitz  # PyMuPDF\n",
        "import sys\n",
        "from typing import List\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def extract_highlighted_texts(html_file: str) -> List[str]:\n",
        "    \"\"\"Extract text between <highlight> and </highlight> markers, stripping nested HTML tags.\"\"\"\n",
        "    with open(html_file, 'r', encoding='utf-8') as f:\n",
        "        html_content = f.read()\n",
        "    # Use regex to find text between <highlight> and </highlight>\n",
        "    pattern = r'&lt;highlight&gt;(.*?)&lt;/highlight&gt;'\n",
        "    highlighted_texts = re.findall(pattern, html_content, re.DOTALL)\n",
        "    # Strip nested HTML tags and clean up text\n",
        "    cleaned_texts = []\n",
        "    for text in highlighted_texts:\n",
        "        # Parse with BeautifulSoup to remove HTML tags\n",
        "        soup = BeautifulSoup(text, 'html.parser')\n",
        "        cleaned_text = ' '.join(soup.get_text().split())  # Normalize whitespace\n",
        "        if cleaned_text:\n",
        "            cleaned_texts.append(cleaned_text)\n",
        "    return cleaned_texts\n",
        "\n",
        "def add_highlight_to_pdf(pdf_file: str, output_file: str, highlighted_texts: List[str]):\n",
        "    \"\"\"Add highlight annotations to the PDF for each highlighted text.\"\"\"\n",
        "    doc = fitz.open(pdf_file)\n",
        "    highlights_added = False\n",
        "\n",
        "    for target_text in highlighted_texts:\n",
        "        found = False\n",
        "        # Search each page for the target text\n",
        "        for page_num in range(len(doc)):\n",
        "            page = doc[page_num]\n",
        "            # Search for the exact text (case-insensitive)\n",
        "            rects = page.search_for(target_text, flags=fitz.TEXTFLAGS_SEARCH )\n",
        "            if rects:\n",
        "                # Highlight all found instances on this page\n",
        "                for rect in rects:\n",
        "                    annot = page.add_highlight_annot(rect)\n",
        "                    if annot:\n",
        "                        annot.update()\n",
        "                        # print(f\"Highlighted text: '{target_text}' on page {page_num + 1} at coordinates \"\n",
        "                        #       f\"({rect.x0:.2f}, {rect.y0:.2f}, {rect.x1:.2f}, {rect.y1:.2f})\")\n",
        "                        highlights_added = True\n",
        "                found = True\n",
        "        if not found:\n",
        "            print(f\"Warning: Could not find match for '{target_text}' in PDF. Skipping.\")\n",
        "\n",
        "    if highlights_added:\n",
        "        doc.save(output_file, garbage=4, deflate=True)\n",
        "        print(f\"PDF with highlights is saved to {output_file}\")\n",
        "    else:\n",
        "        print(\"No highlights were added to the PDF.\")\n",
        "\n",
        "    doc.close()\n",
        "\n",
        "def main(html_file: str, pdf_file: str, output_file: str):\n",
        "    # Step 1: Extract highlighted texts from HTML\n",
        "    highlighted_texts = extract_highlighted_texts(html_file)\n",
        "    if not highlighted_texts:\n",
        "        print(\"No highlighted texts found in HTML.\")\n",
        "        return\n",
        "\n",
        "    # Step 2: Add highlights to PDF\n",
        "    add_highlight_to_pdf(pdf_file, output_file, highlighted_texts)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if len(sys.argv) != 4:\n",
        "        print(\"Usage: python3 highlight_pdf.py input.html input.pdf output.pdf\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    html_file, pdf_file, output_file = sys.argv[1], sys.argv[2], sys.argv[3]\n",
        "    main(html_file, pdf_file, output_file)\n",
        "''')\n",
        "\n",
        "!python3 highlight.py {HTML_FILENAME} {HTML_OUT_FILENAME}\n",
        "!python3 highlight_pdf.py {HTML_FILENAME} {PDF_FILENAME} {PDF_OUT_FILENAME}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title download\n",
        "from google.colab import files\n",
        "files.download(PDF_OUT_FILENAME)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5W6O2GjBnAjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kuFig3Qu8GZ-"
      },
      "outputs": [],
      "source": [
        "#@title display paper\n",
        "# from IPython.core.display import display, HTML\n",
        "# with open(HTML_OUT_FILENAME, \"r\") as f:\n",
        "#     display(HTML(f.read()))\n",
        "\n",
        "import requests\n",
        "import io\n",
        "import base64\n",
        "from pdf2image import convert_from_bytes\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def display_scrollable_pdf(filename, width=800, height=450):\n",
        "\n",
        "    try:\n",
        "        with open(filename, \"rb\") as f:\n",
        "            pdf_bytes = f.read()\n",
        "        images = convert_from_bytes(pdf_bytes)\n",
        "\n",
        "        img_tags = []\n",
        "        for img in images:\n",
        "            buffer = io.BytesIO()\n",
        "            img.save(buffer, format='PNG')\n",
        "            img_base64 = base64.b64encode(buffer.getvalue()).decode()\n",
        "            img_tag = f'<img src=\"data:image/png;base64,{img_base64}\" style=\"width:100%; margin-bottom:10px;\" />'\n",
        "            img_tags.append(img_tag)\n",
        "\n",
        "        html_code = f\"\"\"\n",
        "        <div style=\"width:{width}px; height:{height}px; overflow:auto; border:1px solid #ccc;\n",
        "                    padding:10px; border-radius:8px;\">\n",
        "            {''.join(img_tags)}\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        display(HTML(html_code))\n",
        "\n",
        "    except Exception as e:\n",
        "        display(HTML(f\"<div style='color:red;'>Error loading PDF: {e}</div>\"))\n",
        "\n",
        "display_scrollable_pdf(\n",
        "    f\"/content/{PDF_OUT_FILENAME}\",\n",
        "    width=800,\n",
        "    height=450\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXTZYbTdPTd248nKJmlGiE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}